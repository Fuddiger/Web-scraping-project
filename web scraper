import csv
import re
import requests
from bs4 import BeautifulSoup as bs
from datetime import datetime

#Sites from which to pull news articles
def get_sites():
    sites = ['https://globalnews.ca/montreal/', 'https://abcnews.go.com/', 'https://foxnews.com']
    return sites

#Returns a set for each  news site containing all the links for news articles
def get_links(site):
    links = set()
    with requests.Session() as s:
        response = s.get(site)
        soup = bs(response.text,'lxml',)
        if site == 'https://globalnews.ca/montreal/':
            for tag in soup.find_all('a', href=re.compile('/news/')):
                links.add(tag['href'])
        elif site == 'https://abcnews.go.com':
            for tag in soup.find_all('a', href=re.compile('^https\S*\d{8}$')):
                links.add(tag['href'])
        elif site == 'https://foxnews.com':
            for tag in soup.find_all('a', href=re.compile('-[0-9|a-z]+-[0-9|a-z]+-[0-9|a-z]+$')):
                #A lot of links pulled from Fox News are missing the 'https:' at the beginning
                if re.search(r'^https', tag['href']):
                    links.add(tag['href'])
                else:
                    repaired_link = 'https:' + tag['href']
                    links.add(repaired_link)
    return links

#makes a soup for a news article link
def link_soup(link):
    with requests.Session() as s:
        response = s.get(link)
        soup = bs(response.text, 'lxml')
        return soup

#Scrapes the publication date from an article formatted for the site it comes from and returns it as a date object
def scrape_date(soup):
    if site == 'https://globalnews.ca/montreal/':
        try:
            date = soup.find('span', string= re.compile('Posted')).get_text(strip=True)
            strp_date = datetime.strptime(date, 'Posted %B %d, %Y %I:%M %p')
            return strp_date
        except:
            print(soup.title.get_text(strip=True))
            pass
    elif site == 'https://abcnews.go.com/':
        try:
            date = soup.find('div', class_='xTlfF Vxqj').get_text(separator=' ', strip=True)
            strp_date = datetime.strptime(date, '%B %d, %Y, %I:%M %p')
            return strp_date
        except:
            print(soup.title.get_text(strip=True))
            pass
    elif site == 'https://foxnews.com':
        try:
            date = soup.find('div', class_='article-date').get_text(separator=' ',strip=True)
            strp_date = datetime.strptime(date, 'Published %B %d, %Y %I:%M%p EST')
            return strp_date
        except:
            print(soup.title.get_text(strip=True))
            pass

#Returns the title of the article as a string
def scrape_title(soup):
    title = soup.title.get_text(strip=True)
    return title

#Returns the stripped article text
def scrape_text(soup):
    text = soup.get_text(separator=' ', strip=True)
    return text

#Writes the data to a file to be processed later
def data_write(title, date, text):
    with open('scraper.txt', 'a', newline='', encoding='utf-8') as a:
        writer = csv.writer(a)
        writer.writerow([title])
        writer.writerow([date])
        writer.writerow([text, '\n'])

if __name__ == '__main__':
    sites = get_sites()
    for site in sites:
        links = get_links(site)
        for link in links:
            soup = link_soup(link)
            title = scrape_title(soup)
            date = scrape_date(soup)
            text = scrape_text(soup)
            data_write(title, date, text)

